\chapter{Benchmarks}
\label{sec:benchmarks}

The following sections will measure the impact the jit compilation has on
selected workloads.

Benchmark results may be subject to various influences, including the workload
on the system conducting the benchmarks, insufficiently sized data sets for
comprehensive and accurate testing, as well as comparing inherently dissimilar
benchmarks. Most of the aforementioned can be mitigated by using the
\texttt{testing} package included in the go programming languages standard
library \cite{go_testing}. 

To avoid the influences of the current workload of the system the tests are
performed many times, therefore accounting for statistical outliers and
external system influences on the test, which furthermore accounts for the
possibility of choosing insufficiently sized data sets.

By benchmarking the execution of the same given input with the JIT-compiler
enabled and with the JIT-compiler disabled an inherently comparable data set is
created due to the shared purpose of evaluating the runtime performance under
differing runtime configurations. Therefore, conducting benchmarks under the
two previously mentioned configurations and comparing the results is a valid
evaluation of the two benchmarks.

The benchmarks simulate a hot path by executing a given operations for a given
iteration count and running the benchmark itself multiple times using the
command line benchmarking tool
\href{https://github.com/sharkdp/hyperfine}{\textit{hyperfine}}.


\section{Arithmetics}

\begin{listing}[H]
    \begin{minted}[breaklines]{kotlin}
func b(a)
    a*a/25*a-12+a/a*a*a*a/25*a-12+a/a*a*a*a/25*a
    -12+a/a*a*a*a/25*a-12+a/a*a*a*a/25*a-12+a/a*a
    *a*a/25*a-12+a/a*a*a*a/25*a-12+a/a*a*a*a/25
    *a-12+a/a*a*a*a/25*a-12+a/a*a*a*a/25*a-12+a/a
    *a*a*a/25*a-12+a/a*a*a*a/25*a-12+a/a*a;
let s = list(100_000).map(b).sum();
s
    \end{minted}
    \caption{Heavy load arithmetic operations}
    \label{code:benchmark-arithmetics}
\end{listing}

Benchmarking the performance of arithmetic operations allows for a first
execution efficiency evaluation of the language runtime. The benchmark using
\autoref{code:benchmark-arithmetics} results of up to $14.51\textrm{x}$
improvement ($0.94\textrm{s}$ instead of $13.64\textrm{s}$). While the original
runtime scales linearly and proportionally to the input, the runtime supported
by the JIT-compiler scales at an almost constant rate, see
\autoref{chart:arithmetic-benchmarks} and \autoref{table:benchmark-arithmetic}.

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c}
        Iterations & Mean Execution Time & Mean Execution Time (JIT) & $\Delta$ & Improvement \\ 
        \hline
        100k & 00.28s & 0.20s & 00.08s & 01.40x \\ 
        500k & 01.37s & 0.26s & 01.11s & 05.27x \\
        1mio & 02.73s & 0.34s & 02.39s & 08.03x \\
        5mio & 13.64s & 0.94s & 12.70s & 14.51x \\
    \end{tabular}
    \caption{Arithmetic operations benchmark results }
    \label{table:benchmark-arithmetic}
\end{table}


\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            title={Arithmetic Operations},
            xlabel={Iterations},
            ylabel={Mean Execution Time (s)},
            legend style={at={(0.5,-0.2)},anchor=north},
            grid style={dotted},
            major grid style={dotted,black!50},
            minor grid style={dotted,black!20},
            nodes near coords,
            ymin=-3,
            ]
            
            \pgfplotstableread[col sep=comma]{benchmarks/arithmetics.csv}\arithmeticBenchmarks
            \pgfplotstableread[col sep=comma]{benchmarks/arithmeticsJIT.csv}\arithmeticBenchmarksJIT

            \addplot[color=blue,mark=*] table[x=command, y=mean] {\arithmeticBenchmarks};
            \addplot+[color=red,mark=square*,nodes near coords style={rotate=-45,anchor=north west}] table[x=command, y=mean] {\arithmeticBenchmarksJIT};
            \legend{JIT Enabled=false, JIT Enabled=true}
        \end{axis}
    \end{tikzpicture}
    \caption{Benchmark: Arithmetic operations}
    \label{chart:arithmetic-benchmarks}
\end{figure}


\section{String operations}

\begin{listing}[H]
    \begin{minted}[breaklines]{kotlin}
func b(a)
    a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a+a;
let s = list(100_000).map(e->e.string()).map(b).size();
s
    \end{minted}
    \caption{Heavy load string concatenating}
    \label{code:benchmark-string}
\end{listing}

Merging strings is an often used language feature, therefore making the need
for high efficiency evident. This benchmark aims to simulate a real world use
with heavy load, similar to the benchmark performed before. Both
\autoref{table:benchmark-string} and its visualisation
\autoref{chart:benchmark-string} show the performance improvement of at least
$1.43\textrm{x}$ and at most $4.59\textrm{x}$ - resulting in a mean delta,
comparing the current runtime and the runtime enhanced with the JIT, of at most
$11.08\textrm{s}$ and at least $0.10\textrm{s}$.

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c}
        Iterations & Mean Execution Time & Mean Execution Time (JIT) & $\Delta$ & Improvement \\ 
        \hline
        100k & 00.33s & 0.23s & 00.10s & 1.43x  \\
        500k & 01.57s & 0.48s & 01.09s & 3.27x  \\ 
        1mio & 02.99s & 0.77s & 02.22s & 3.89x  \\ 
        5mio & 14.17s & 3.09s & 11.08s & 4.59x\\ 
    \end{tabular}
    \caption{String concatenation benchmark results}
    \label{table:benchmark-string}
\end{table}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            title={String Concatenating},
            xlabel={Iterations},
            ylabel={Mean Execution Time (s)},
            legend style={at={(0.5,-0.2)},anchor=north},
            grid style={dotted},
            major grid style={dotted,black!50},
            minor grid style={dotted,black!20},
            nodes near coords,
            ymin=-3,
            ]
            
            \pgfplotstableread[col sep=comma]{benchmarks/strings.csv}\stringBenchmark
            \pgfplotstableread[col sep=comma]{benchmarks/stringsJIT.csv}\stringBenchmarkJIT

            \addplot[color=blue,mark=*] table[x=command, y=mean] {\stringBenchmark};
            \addplot+[color=red,mark=square*,nodes near coords style={rotate=-45,anchor=north west}] table[x=command, y=mean] {\stringBenchmarkJIT};
            \legend{JIT Enabled=false, JIT Enabled=true}
        \end{axis}
    \end{tikzpicture}
    \caption{Benchmark: String concatenating}
    \label{chart:benchmark-string}
\end{figure}

\section{Real world workloads}

Contrary to the before examined language features, this benchmark focusses on
common operations performed on large datasets, such as aggregating values,
reading and overwriting data, chaining list operations and working with lists
of objects. Due to the mixture of operations featured in this benchmark the
resulting numbers are a combination of different factors.

The improvements for smaller iterations, such as 100 thousand and 500 thousand,
can be considered negligible. For the larger iterations the JIT improves the
performance by at least $0.3\textrm{s}$ ($1.24\textrm{x}$) and at most
$2.42\textrm{s}$ ($1.431\textrm{x}$).

\begin{listing}[H]
    \begin{minted}[breaklines]{kotlin}
list(100_000)
    .filter(e -> e >= 1)
    .map(e -> ((1024*(1024-e))/(e+1024))+(e*e+e*e-e*e+e*e))
    .map(e -> {Key: "Number", Value: e})
    .map(e -> e.Value)
    .map(e -> e.string().len().string())
    .map(e -> e+e+e+e+e+e+e)
    .last()
    \end{minted}
    \caption{Real world heavy load benchmark}
    \label{code:benchmark-realworld}
\end{listing}

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c}
        Iterations & Mean Execution Time & Mean Execution Time (JIT) & $\Delta$ & Improvement \\ 
        \hline
        100k & 0.18s & 0.18s & 0.00s & 0.000x \\
        500k & 0.87s & 0.82s & 0.05s & 1.061x \\
        1mio & 1.68s & 1.36s & 0.32s & 1.240x \\
        5mio & 8.04s & 5.62s & 2.42s & 1.431x\\
    \end{tabular}
    \label{table:benchmark-realworld}
    \caption{Real world heavy load benchmark results}
\end{table}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            title={Heavy load benchmark},
            xlabel={Iterations},
            ylabel={Mean Execution Time (s)},
            legend style={at={(0.5,-0.2)},anchor=north},
            grid style={dotted},
            major grid style={dotted,black!50},
            minor grid style={dotted,black!20},
            nodes near coords,
            ymin=-3,
            ]
            
            \pgfplotstableread[col sep=comma]{benchmarks/real.csv}\realBenchmark
            \pgfplotstableread[col sep=comma]{benchmarks/realJIT.csv}\realBenchmarkJIT

            \addplot[color=blue,mark=*] table[x=command, y=mean] {\realBenchmark};
            \addplot+[color=red,mark=square*,nodes near coords style={rotate=-45,anchor=north west}] table[x=command, y=mean] {\realBenchmarkJIT};
            \legend{JIT Enabled=false, JIT Enabled=true}
        \end{axis}
    \end{tikzpicture}
    \caption{Benchmark: Real world heavy load benchmark}
    \label{chart:benchmark-realworld}
\end{figure}

\section{Determining the \texttt{JIT\_CONSTANT}}
\label{sec:jit-constant-discussion}

The jit constant, introduced in \autoref{sec:meta-tracing-jit-constant}, is
used to establish a optimal relation between the possible performance
improvements and the negative performance impact of invoking the compilation a
function. Therefore the threshold acts as the criteria for categorizing a given
function as a compilation target for the jit compiler. To find the optimal
relation between compiling a function too early which could result in degraded
overall performance or compiling the a function too late, which does not allow
the JIT to enable its full potential.

The benchmark to determine the aforementioned is conducted by executing the
benchmark representing the real world workload, shown in
\autoref{code:benchmark-realworld}, with differing values for the
\texttt{JIT\_CONSTANT}, ranging from a thousand to one million and recording
the delta between the runtime with and without the JIT enabled for each
\texttt{JIT\_CONSTANT} value. \autoref{table:benchmark-realworld-jit} displays
the results of the measurements while .

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c}
        Constant & Iterations & Mean Execution Time & $\Delta$ \\ 
        \hline
        Off         & 100k & 0.18s & 0.00s \\
                    & 500k & 0.87s & 0.00s \\
                    & 1mio & 1.68s & 0.00s \\
                    & 5mio & 8.04s & 0.00s \\
        \hline
        1,000       & 100k & 0.18s & 0.00s \\
                    & 500k & 0.82s & 0.05s \\
                    & 1mio & 1.36s & 0.32s \\
                    & 5mio & 5.62s & 2.42s \\
        \hline
        10,000      & 100k & 0.18s & 0.00s \\
                    & 500k & 0.83s & 0.04s \\
                    & 1mio & 1.36s & 0.32s \\
                    & 5mio & 5.57s & 2.47s \\
        \hline
        100,000     & 100k & 0.18s & 0.00s \\
                    & 500k & 0.85s & 0.02s \\
                    & 1mio & 1.42s & 0.26s \\
                    & 5mio & 5.64s & 2.40s \\
        \hline
        250,000     & 100k & 0.18s & 0.00s \\
                    & 500k & 0.86s & 0.01s \\
                    & 1mio & 1.51s & 0.17s \\
                    & 5mio & 5.79s & 2.25s \\
        \hline
        500,000     & 100k & 0.18s & 0.00s \\
                    & 500k & 0.86s & 0.01s \\
                    & 1mio & 1.63s & 0.05s \\
                    & 5mio & 5.93s & 2.11s \\
    \end{tabular}
    \label{table:benchmark-realworld-jit}
    \caption{\texttt{JIT\_CONSTANT} benchmark result}
\end{table}

\autoref{chart:benchmark-realworld-jit} notates the importance of letting the
runtime execute functions that aren't executed often for this is underlined by
the results for $100,000$ function invocations. In this case the runtime is as
fast as the JIT, therefore the startup cost is not justifiable. 

The first differences in total runtime performance can be observed for
$500,000$ function calls. The runtime starts to slow down in comparison to the
JIT results. Smaller \texttt{JIT\_CONSTANT} values result in approximately the
same values. However, Most of these values are faster than the runtime. 

Signification speed-ups can be identified once the invocation count exceeds the
one million mark. The results for the \texttt{JIT\_CONSTANT} values $1000$ and
$10,000$ both enable execution time savings of around $0.32$ seconds or
$320$ms. All larger values for the \texttt{JIT\_CONSTANT} result in less
substantial improvements.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}

        \pgfplotstableread[col sep=comma]{benchmarks/real.csv}\realBenchmark
        \pgfplotstableread[col sep=comma]{benchmarks/realJIT.csv}\realBenchmarkJIT
        \pgfplotstableread[col sep=comma]{benchmarks/realJIT10k.csv}\realBenchmarkJITten
        \pgfplotstableread[col sep=comma]{benchmarks/realJIT100k.csv}\realBenchmarkJIThundred
        \pgfplotstableread[col sep=comma]{benchmarks/realJIT250k.csv}\realBenchmarkJITtwohundred
        \pgfplotstableread[col sep=comma]{benchmarks/realJIT500k.csv}\realBenchmarkJITfivehundred

        \begin{axis}[
            title={JIT\_CONSTANT Benchmark},
            xlabel={Iterations},
            ylabel={Mean Execution Time (s)},
            legend style={at={(0.02,0.98)},anchor=north west},
            grid style={dotted},
            major grid style={dotted,black!50},
            minor grid style={dotted,black!20},
            ybar,
            ymax=10,
            width=15cm,
            bar width=12pt,
            enlarge x limits={abs=2cm},
            xtick=data,
            nodes near coords,
            every node near coord/.append style={
                anchor=west,
                rotate=90
            },
            xticklabels={100k, 500k, 1mio, 5mio}
        ]


        \addplot table[x expr=\coordindex, y=mean] {\realBenchmark};
        \addplot table[x expr=\coordindex, y=mean] {\realBenchmarkJIT};
        \addplot table[x expr=\coordindex, y=mean] {\realBenchmarkJITten};
        \addplot table[x expr=\coordindex, y=mean] {\realBenchmarkJIThundred};
        \addplot[color=green!40!black,fill=green!70!black!50] table[x expr=\coordindex, y=mean] {\realBenchmarkJITtwohundred};
        \addplot[color=red!90!white,fill=red!50!white] table[x expr=\coordindex, y=mean] {\realBenchmarkJITfivehundred};
        \legend{Jit disabled, Constant 1000, Constant 10000, Constant 100000, Constant 250000, Constant 500000}
        \end{axis}
    \end{tikzpicture}

    \caption{Benchmark: \texttt{JIT\_CONSTANT} benchmark}
    \label{chart:benchmark-realworld-jit}
\end{figure}

Due to the nature of a JIT compiler it targets code chunks that are executed
more often, thus justifying the start up and compilation cost. To simulate this
intent, the last tested iteration count was chosen to be five million
iterations. This substantiates the previous observations of lower values for
the \texttt{JIT\_CONSTANT} resulting in larger performance wins. For five
million operations, all JIT compiled tests resulted in at least a saving of
$2.11$s or $2110$ms. The largest improvements are surveyed for the
\texttt{JIT\_CONSTANT} value of $10,000$, compared to the runtime this value
enabled the improvement of $2.47$s or $2470$ms, resulting in a runtime
reduction of $30.72\%$ or $1.443$ times faster.

The conclusion of these benchmark is to change the \texttt{JIT\_CONSTANT} from
its previously set value of $1,000$ to the determined optimal value of
$10,000$.

